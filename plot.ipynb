{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8eeba07-157e-44d2-9b70-75365a38771d",
   "metadata": {},
   "source": [
    "### Loss vs. norm plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd71a90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584fe9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.fitting import Config, build_minima_df\n",
    "from utils.plotting import plot_minima, plot_parabola_grid, plot_interactive_horizon_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ad36a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for paths\n",
    "# BASE = \"normalisation-residual-only\" # 'Adam' // 'normalisation-residual-only' // 'lr-bs-scan'\n",
    "# SCALING_PREFIX = 'base' # 'base' // 'x4-width' // 'x8-depth'\n",
    "# POSTFIX = \"\"\n",
    "# MOMENTUM = 0.1\n",
    "# DECAYED = True\n",
    "# SEEDS = [30] # None for all // [30] for one \n",
    "\n",
    "# # filtering\n",
    "# # HORIZONS = np.logspace(31, 37, 4, base=2)\n",
    "# # HORIZONS = [2_868_903_936, 11_475_615_744, 45_902_462_976, 183_609_851_904]\n",
    "# HORIZONS = [2**31, 2**33, 2**35, 1.25*2**35] # 1.25*np.logspace(31, 35, 3, base=2)\n",
    "# MAX_LOSS = 11.765\n",
    "\n",
    "# ##### Residual-only\n",
    "# FROM_FIT = True\n",
    "# OPTIMUM_FROM_CLOSEST = False\n",
    "# C_FIXED = None\n",
    "# FIT_K = 5\n",
    "# FIT_K_BY = \"x\"\n",
    "# AVG_REL_FROM = -3\n",
    "# AVG_REL_TO = 3\n",
    "# AVERAGE_H = HORIZONS # [2**33, 2**34, 2**35, 2**36, 2**37] \n",
    "# AVERAGE_BS = [2**3, 2**4, 2**5, 2**6, 2**7, 2**8, 2**9, 2**10, 2**11, 2**12] # 2**8, 2**9, 2**10\n",
    "# SKIP_FIT = [(2**35, 2**5), (2**35, 2**6), (2**35, 2**7), (2**35, 2**8), (2**35, 2**10),\n",
    "#             (1.25*2**35, 2**5), (1.25*2**35, 2**6), (1.25*2**35, 2**7),  (1.25*2**35, 2**8), ] #  (2**35, 2**7), (1.25*2**35, 2**7)\n",
    "\n",
    "# # #### Adam\n",
    "# # # fit cfg\n",
    "# # FROM_FIT = True\n",
    "# # OPTIMUM_FROM_CLOSEST = False\n",
    "# # C_FIXED = None\n",
    "# # FIT_K = 4\n",
    "# # FIT_K_BY = \"x\"\n",
    "# # AVG_REL_FROM = -5\n",
    "# # AVG_REL_TO = 5\n",
    "# # AVERAGE_H = HORIZONS # [2**33, 2**34, 2**35, 2**36, 2**37] \n",
    "# # AVERAGE_BS = [2**3, 2**4, 2**5, 2**6, 2**7, 2**8, 2**9, 2**10, 2**11, 2**12] # 2**8, 2**9, 2**10\n",
    "# # SKIP_FIT = [(2**35, 2**5), (1.25*2**35, 2**5), (2**31, 2**7), (2**33, 2**7), ] #  (2**35, 2**7), (1.25*2**35, 2**7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9826e7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE = \"lr-bs-scan-rus\"\n",
    "# SCALING_PREFIX = 'base' # 'base' // 'x4-width' // 'x8-depth'\n",
    "# POSTFIX = \"\"\n",
    "# MOMENTUM = 1.0\n",
    "# DECAYED = False\n",
    "# SEEDS = None # None for all // [30] for one \n",
    "\n",
    "# # filtering\n",
    "# HORIZONS = np.logspace(31, 35, 3, base=2)\n",
    "# # HORIZONS = [2_868_903_936, 11_475_615_744, 45_902_462_976, 183_609_851_904]\n",
    "# MAX_LOSS = 11.765\n",
    "\n",
    "# # fit cfg\n",
    "# FROM_FIT = True\n",
    "# OPTIMUM_FROM_CLOSEST = False\n",
    "# C_FIXED = None\n",
    "# FIT_K = 7\n",
    "# FIT_K_BY = \"x\"\n",
    "# AVG_REL_FROM = -3\n",
    "# AVG_REL_TO = 3\n",
    "# AVERAGE_H = [2**33, 2**34, 2**35, 2**36, 2**37] \n",
    "# AVERAGE_BS = [2**3, 2**4, 2**5, 2**6, 2**7, 2**8, 2**9, 2**10, ] # 2**8, 2**9, 2**10\n",
    "# SKIP_FIT = [(2**35, 2**4), (2**33, 2**3), (2**35, 2**3),] # (2**33, 2**9), (2**33, 2**10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2b9c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for paths\n",
    "BASE = \"lr-bs-scan\"\n",
    "SCALING_PREFIX = 'base' # 'base' // 'x4-width' // 'x8-depth'\n",
    "POSTFIX = \"\"\n",
    "MOMENTUM = 1.0\n",
    "DECAYED = False\n",
    "SEEDS = [30] # None for all // [30] for one \n",
    "\n",
    "# filtering\n",
    "HORIZONS = np.logspace(31, 37, 4, base=2)\n",
    "# HORIZONS = [2_868_903_936, 11_475_615_744, 45_902_462_976, 183_609_851_904]\n",
    "MAX_LOSS = 11.765\n",
    "\n",
    "# fit cfg\n",
    "FROM_FIT = True\n",
    "OPTIMUM_FROM_CLOSEST = False\n",
    "C_FIXED = MAX_LOSS\n",
    "FIT_K = 7\n",
    "FIT_K_BY = \"x\"\n",
    "AVG_REL_FROM = -1\n",
    "AVG_REL_TO = 1\n",
    "AVERAGE_H = [2**33, 2**34, 2**35, 2**36, 2**37] \n",
    "AVERAGE_BS = [2**3, 2**4, 2**5, 2**6, 2**7, ] # 2**8, 2**9, 2**10\n",
    "SKIP_FIT = [] # (2**33, 2**9), (2**33, 2**10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fa76b8-9fb1-4319-bc1b-f6c589e91fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SEEDS is None:\n",
    "    seed_part = \"-seeds\"\n",
    "elif len(SEEDS) == 1:\n",
    "    seed_part = f\"-seed-{SEEDS[0]}\"\n",
    "else:\n",
    "    raise ValueError(\"Only one seed supported\")\n",
    "CSV_PATH = f'data/{BASE}-{SCALING_PREFIX}-momentum-{MOMENTUM}{'-decayed' if DECAYED else ''}-preprocessed{seed_part}{POSTFIX}.csv'\n",
    "\n",
    "cfg = Config(\n",
    "    csv_path=CSV_PATH,\n",
    "    horizons=HORIZONS,\n",
    "    max_loss=MAX_LOSS,\n",
    "    from_fit=FROM_FIT,\n",
    "    c_fixed=C_FIXED,\n",
    "    optimum_from_closest=OPTIMUM_FROM_CLOSEST,\n",
    "    fit_k=FIT_K, \n",
    "    fit_k_by=FIT_K_BY,\n",
    "    avg_rel_from=AVG_REL_FROM,\n",
    "    avg_rel_to=AVG_REL_TO,\n",
    "    average_h=AVERAGE_H,\n",
    "    average_bs=AVERAGE_BS,\n",
    "    skip_fit=SKIP_FIT,\n",
    "    strict_avg=True,\n",
    "    bs_size_base=50,\n",
    "    bs_size_factor=1.85,\n",
    "    figsize=(9, 8),\n",
    "    # legend_models_loc=\"upper center\",\n",
    "    legend_models_bbox=(0.4, .98),\n",
    "    # legend_bs_loc=\"lower left\",\n",
    "    # legend_bs_bbox=(0.545, .78),\n",
    "    legend_bs_bbox=(0.01, .25),\n",
    "    use_constrained_layout=True,\n",
    "    line_width=4.,\n",
    "    legend_fontsize=16,\n",
    "    axis_label_fontsize=23,\n",
    "    tick_label_fontsize=23,\n",
    ")\n",
    "df = pd.read_csv(cfg.csv_path)\n",
    "minima = build_minima_df(df, cfg)\n",
    "\n",
    "minima = minima.query('(bs >= 8) and (bs <= 4096)')\n",
    "# minima.to_csv(f'data/minima-{SCALING_PREFIX}-from-fit-{FROM_FIT}-c-{C_FIXED}-aver-{AVG_REL_FROM}.csv', index=False)\n",
    "\n",
    "fig, ax = plot_minima(minima, cfg)\n",
    "if MOMENTUM == 0.0:\n",
    "    ax.set_xlim(4.8, 9.5)\n",
    "    ax.set_ylim(3.7, 6.6)\n",
    "elif \"residual-only\" in BASE:\n",
    "    ax.set_xlim(2., 4.)\n",
    "    ax.set_ylim(3.5, 4.5)\n",
    "elif \"thai\" in BASE:\n",
    "    ax.set_xlim(5., 9.)\n",
    "    ax.set_ylim(2.1, 3.5)\n",
    "elif \"rus\" in BASE:\n",
    "    ax.set_xlim(5., 10.5)\n",
    "    ax.set_ylim(2.75, 4.5)\n",
    "else:\n",
    "    ax.set_xlim(6., 11.5)\n",
    "    ax.set_ylim(3.65, 4.5)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "# fig.savefig(f'plots/loss-vs-norm-{BASE}-{SCALING_PREFIX}-from-fit-{FROM_FIT}-momentum-{MOMENTUM}-decayed-{DECAYED}{POSTFIX}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef22fb62",
   "metadata": {},
   "source": [
    "### Individuals fits for diagnostics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6988c7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plot_parabola_grid(df, cfg)\n",
    "\n",
    "for ax in axes.flat:\n",
    "    if 'thai' in BASE:\n",
    "        ax.set_ylim(2.1, 4.)  \n",
    "    elif 'rus' in BASE:\n",
    "        ax.set_ylim(2.6, 5.5)\n",
    "    else:  \n",
    "        ax.set_ylim(3.35, 7.)  \n",
    "\n",
    "plt.show()\n",
    "# fig.savefig(f'plots/fits-{BASE}-{SCALING_PREFIX}-from-fit-{FROM_FIT}-momentum-{MOMENTUM}-decayed-{DECAYED}{POSTFIX}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91febcb5",
   "metadata": {},
   "source": [
    "### 3D plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1399ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_interactive_horizon_scatter(\n",
    "    df,\n",
    "    horizon=2**33,\n",
    "    loss_range=(3.5, 8.0),\n",
    "    fig_height_px=800,\n",
    "    fig_width_px=950,\n",
    "    norm_col=\"output_norm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2fa43e",
   "metadata": {},
   "source": [
    "### Norm variation with LR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3356b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88cf6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/lr-bs-scan-base-momentum-1.0-preprocessed-seed-30.csv\")\n",
    "df_ = df.query('(bs == 128) and (horizon == 2**33)')\n",
    "\n",
    "# Find the optimum point (minimum loss)\n",
    "opt_idx = df_['train_loss'].idxmin()\n",
    "opt_norm = df_.loc[opt_idx, 'output_norm']\n",
    "opt_loss = df_.loc[opt_idx, 'train_loss']\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(df_['output_norm'], df_['train_loss'], s=100, c=np.log2(df_['lr']), cmap='viridis')\n",
    "cbar = plt.colorbar(scatter, label=r'$\\log_{2}(\\eta)$')\n",
    "\n",
    "# Add dashed lines to emphasize the optimum\n",
    "plt.axvline(x=opt_norm, color='black', linestyle='--', linewidth=3, alpha=0.7, label='Optimum')\n",
    "plt.axhline(y=opt_loss, color='black', linestyle='--', linewidth=3, alpha=0.7)\n",
    "\n",
    "# # Highlight the optimum point\n",
    "# plt.scatter(opt_norm, opt_loss, color='red', s=100, marker='*', edgecolor='black', linewidth=1, zorder=5)\n",
    "\n",
    "# Set axis labels with font size\n",
    "plt.xlabel(r'||$W_\\mathrm{out}$||$_{\\mathrm{RMS} \\to \\infty}$', fontsize=22)\n",
    "plt.ylabel('Train Loss', fontsize=22)\n",
    "\n",
    "# Set tick label sizes\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "# Set colorbar label and tick sizes\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "cbar.set_label(r'$\\log_{2}(\\eta)$', fontsize=22)\n",
    "\n",
    "plt.xscale('log', base=2)\n",
    "plt.title(r'$B=128$ samples, $D=2^{33}$ tokens', fontsize=22)\n",
    "# plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig('plots/lr-norm-variation.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a588832e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7800f46a",
   "metadata": {},
   "source": [
    "### Norm growth for different (LR, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0d7ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd031cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.plotting import plot_norm_vs_horizon_by_lr_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfb6d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/lr-bs-scan-base-momentum-1.0-preprocessed-seed-30.csv\")\n",
    "df = df.query('step > 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2ac1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_values = [2**-7, 2**-5, 2**-3, 2**-1]  # Adjust based on your data\n",
    "bs_values = [32, 128, 512, 2048]     # Adjust based on your data\n",
    "x_col = 'horizon'\n",
    "\n",
    "fig, ax = plot_norm_vs_horizon_by_lr_bs(df, x_col=x_col, \n",
    "                                        lr_values=lr_values, bs_values=bs_values)\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig(f'plots/norm-evolution-vs-{x_col}-base.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54fb06b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb1cb745",
   "metadata": {},
   "source": [
    "### Optimal LR vs. B fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e829c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34656884",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is from presaved minima files\n",
    "### Ignore this cell if you want to plot for minima dataframe derived above\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Find all CSV files starting with \"data/minima\"\n",
    "minima_files = glob.glob(\"data/minima*.csv\")\n",
    "print(f\"Found {len(minima_files)} minima files:\")\n",
    "for file in minima_files:\n",
    "    print(f\"  {file}\")\n",
    "\n",
    "# Read all dataframes\n",
    "dataframes = []\n",
    "for file in minima_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Combine all dataframes and group by horizon and bs to average lr\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Group by horizon and bs, then calculate mean and std of lr and keep other columns\n",
    "# We'll take the first value for non-lr columns (assuming they're consistent)\n",
    "minima = combined_df.groupby(['horizon', 'bs']).agg({\n",
    "    'lr': ['mean', 'std'],\n",
    "    **{col: 'first' for col in combined_df.columns if col not in ['lr', 'horizon', 'bs']}\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten the multi-level column names\n",
    "minima.columns = [f'{col[0]}_{col[1]}' if col[1] else col[0] for col in minima.columns]\n",
    "\n",
    "# Rename the lr columns for clarity\n",
    "minima = minima.rename(columns={'lr_mean': 'lr', 'train_loss_first': 'train_loss'})\n",
    "print(f\"\\nCombined dataframe shape: {minima.shape}\")\n",
    "print(f\"Columns: {list(minima.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ce5401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from utils.plotting import plot_lr_bs_fit\n",
    "\n",
    "minima = minima.query('(bs >= 32) and (bs <= 2048)')\n",
    "minima = minima.query('horizon >= 2**31')\n",
    "res = plot_lr_bs_fit(minima, \n",
    "                     lr_col='lr', bs_col='bs', horizon_col='horizon', loss_col='train_loss',\n",
    "                     marker_size=15, legend_marker_size=160, best_marker_size=1200,\n",
    "                     legend_fontsize=16, axis_label_fontsize=23, tick_label_fontsize=23,\n",
    "                     figsize=(9, 8), min_alpha=0.2, \n",
    "                     )\n",
    "fig = res[\"fig\"]\n",
    "plt.show()\n",
    "# fig.savefig(f'plots/lr-vs-bs-base-from-fit-True.pdf')\n",
    "# fig.savefig(f'plots/lr-vs-bs-{SCALING_PREFIX}-from-fit-{FROM_FIT}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d6969e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79655f02",
   "metadata": {},
   "source": [
    "### Optimal B vs D fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c97c290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "src_path = \"data/_minima_more_horizons.csv\"\n",
    "df = pd.read_csv(src_path)\n",
    "\n",
    "# Validate required columns\n",
    "req = [\"horizon\", \"train_loss\", \"bs\"]\n",
    "missing = [c for c in req if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}. Available: {list(df.columns)}\")\n",
    "\n",
    "# Ensure numeric horizon/bs for grouping and logs\n",
    "df[\"horizon_num\"] = pd.to_numeric(df[\"horizon\"], errors=\"coerce\")\n",
    "df[\"bs_num\"] = pd.to_numeric(df[\"bs\"], errors=\"coerce\")\n",
    "\n",
    "# Drop invalids\n",
    "df_clean = df.dropna(subset=[\"horizon_num\", \"train_loss\", \"bs_num\"]).copy()\n",
    "\n",
    "# Select min train_loss per horizon\n",
    "idx = df_clean.groupby(\"horizon_num\")[\"train_loss\"].idxmin()\n",
    "best = df_clean.loc[idx].copy()\n",
    "\n",
    "# Keep strictly positive values for log scaling\n",
    "best = best[(best[\"horizon_num\"] > 0) & (best[\"bs_num\"] > 0)].copy()\n",
    "\n",
    "# Fit in log2 space: log2(bs) = b*log2(horizon) + c\n",
    "x = best[\"horizon_num\"].to_numpy(dtype=float)\n",
    "y = best[\"bs_num\"].to_numpy(dtype=float)\n",
    "lx, ly = np.log2(x), np.log2(y)\n",
    "n = len(lx)\n",
    "xbar, ybar = lx.mean(), ly.mean()\n",
    "Sxx = np.sum((lx - xbar)**2)\n",
    "Sxy = np.sum((lx - xbar)*(ly - ybar))\n",
    "b = Sxy / Sxx\n",
    "c = ybar - b*xbar\n",
    "res = ly - (b*lx + c)\n",
    "RSS = np.sum(res**2)\n",
    "TSS = np.sum((ly - ybar)**2)\n",
    "R2 = 1 - RSS/TSS if TSS > 0 else np.nan\n",
    "\n",
    "# Standard errors (OLS assumptions in log space)\n",
    "s2 = RSS / (n - 2) if n > 2 else np.nan\n",
    "se_b = np.sqrt(s2 / Sxx) if n > 2 else np.nan\n",
    "se_c = np.sqrt(s2 * (1.0/n + (xbar**2)/Sxx)) if n > 2 else np.nan\n",
    "\n",
    "# Transform to original-space scale a = 2^c, with delta-method SE\n",
    "a = 2**c\n",
    "se_a = np.log(2.0) * a * se_c if np.isfinite(se_c) else np.nan\n",
    "\n",
    "# Prepare fitted curve\n",
    "xs = np.logspace(np.log2(x.min()), np.log2(x.max()), num=200, base=2.0)\n",
    "ys = a * (xs**b)\n",
    "\n",
    "# Helper formatter for \"estimate ± s.e.\"\n",
    "def pm(val, se, sig=3):\n",
    "    if not np.isfinite(val) or not np.isfinite(se):\n",
    "        return \"n/a\"\n",
    "    if abs(val) >= 1000 or (0 < abs(val) < 0.01):\n",
    "        return f\"{val:.{sig}f} ± {se:.{sig}f}\"\n",
    "    else:\n",
    "        return f\"{val:.{sig}f} ± {se:.{sig}f}\"\n",
    "\n",
    "legend_lines = [\n",
    "    r\"Fit: $B^\\ast$ = a * Horizon^b\",\n",
    "    f\"b (exponent) = {pm(b, se_b)}\",\n",
    "    f\"a (scale) = {pm(a, se_a)}\",\n",
    "    f\"R² = {R2:.3f}\",\n",
    "]\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(6, 6), dpi=150)\n",
    "plt.scatter(x, y)\n",
    "plt.plot(xs, ys, label=\"\\n\".join(legend_lines))\n",
    "plt.xscale(\"log\", base=2)\n",
    "plt.yscale(\"log\", base=2)\n",
    "plt.xlabel(\"Horizon [tokens]\")\n",
    "plt.ylabel(r\"$B^\\ast$ [samples]\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "# fig.savefig('plots/bs-vs-horizon-log2-log2-fit-more-horizons.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1dca12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4161fc8b",
   "metadata": {},
   "source": [
    "### First horizon to reach optimal norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5858c0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceffd6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.plotting import plot_global_two_param_fit\n",
    "\n",
    "df = pd.read_csv(\"data/lr-bs-scan-base-momentum-1.0-preprocessed-seed-30.csv\")\n",
    "res = plot_global_two_param_fit(df, \n",
    "                                band_center_log2=7, band_eps=0.2,\n",
    "                                bs_min=32, bs_max=1024, \n",
    "                                target_log2_horizons=[31, 32, 33, 34, 35, 36, 37],\n",
    "                                legend_fontsize=16, axis_label_fontsize=23, tick_label_fontsize=23,\n",
    "                                marker_size=16, star_size=30,\n",
    "                                figsize=(9, 8),\n",
    "                                title=\"Base scaling, momentum 1.0\",\n",
    "                                horizon_min=2**31,\n",
    "                                horizon_max=2**37,\n",
    "                                A_fixed=None,\n",
    "                                B_fixed=None,\n",
    "                                overlay_solid_A=-1, overlay_solid_B=1.5,)\n",
    "\n",
    "# res['fig'].savefig(f'plots/horizon-to-norm.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2c4e45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ee55be2",
   "metadata": {},
   "source": [
    "### Scaling up plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90172ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff9d8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.fitting import Config, build_minima_df\n",
    "from utils.plotting import plot_minima_at_horizon_across_models, plot_parabola_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7deb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "\"base\": pd.read_csv(\"data/lr-bs-scan-base-momentum-1.0-preprocessed-seed-30.csv\"),\n",
    "\"x4-w\": pd.read_csv(\"data/lr-bs-scan-x4-width-momentum-1.0-preprocessed-seeds.csv\"),\n",
    "\"x8-d\": pd.read_csv(\"data/lr-bs-scan-x8-depth-momentum-1.0-preprocessed-seeds.csv\"),\n",
    "\"x12-w\": pd.read_csv(\"data/lr-bs-scan-x12-width-momentum-1.0-preprocessed-seeds.csv\"),\n",
    "\"x32-d\": pd.read_csv(\"data/lr-bs-scan-x32-depth-momentum-1.0-preprocessed-seeds.csv\"),\n",
    "}\n",
    "\n",
    "STYLES = {\n",
    "\"base\": {\"color\": \"black\", \"marker\": \"o\", \"linestyle\": \"solid\", \"alpha\": 1.0, \"legend_label\": \"d=256, L=4 (69M)\"},\n",
    "\"x4-w\": {\"color\": \"lightcoral\", \"marker\": \"s\", \"linestyle\": \"solid\", \"alpha\": 1.0, \"legend_label\": \"d=1024, L=4 (314M)\"},\n",
    "\"x12-w\": {\"color\": \"brown\", \"marker\": \"D\", \"linestyle\": \"solid\", \"alpha\": 1.0, \"legend_label\": \"d=3072, L=4 (1.3B)\"},\n",
    "\"x8-d\": {\"color\": \"lightblue\", \"marker\": \"^\", \"linestyle\": \"solid\", \"alpha\": 1.0, \"legend_label\": \"d=256, L=32 (91M)\"},\n",
    "\"x32-d\": {\"color\": \"steelblue\", \"marker\": \"v\", \"linestyle\": \"solid\", \"alpha\": 1.0, \"legend_label\": \"d=256, L=128 (168M)\"},\n",
    "}\n",
    "\n",
    "# filtering\n",
    "HORIZON = 2**33\n",
    "MAX_LOSS = 11.765\n",
    "\n",
    "FROM_FIT = True\n",
    "OPTIMUM_FROM_CLOSEST = False\n",
    "C_FIXED = MAX_LOSS\n",
    "FIT_K = 7\n",
    "FIT_K_BY = \"x\"\n",
    "AVG_REL_FROM = -1\n",
    "AVG_REL_TO = 1\n",
    "AVERAGE_H = [2**33] \n",
    "AVERAGE_BS = [2**5, 2**6, 2**7, ] # 2**8, 2**9, 2**10\n",
    "SKIP_FIT = [] # (2**33, 2**9), (2**33, 2**10)\n",
    "POSTFIX = \"\"\n",
    "\n",
    "cfg = Config(\n",
    "    csv_path=\"\",\n",
    "    horizons=[HORIZON],\n",
    "    max_loss=MAX_LOSS,\n",
    "    from_fit=FROM_FIT,\n",
    "    c_fixed=C_FIXED,\n",
    "    optimum_from_closest=OPTIMUM_FROM_CLOSEST,\n",
    "    fit_k=FIT_K, \n",
    "    fit_k_by=FIT_K_BY,\n",
    "    avg_rel_from=AVG_REL_FROM,\n",
    "    avg_rel_to=AVG_REL_TO,\n",
    "    average_h=AVERAGE_H,\n",
    "    average_bs=AVERAGE_BS,\n",
    "    skip_fit=SKIP_FIT,\n",
    "    strict_avg=True,\n",
    "    bs_size_base=50,\n",
    "    bs_size_factor=1.85,\n",
    "    figsize=(9, 8),\n",
    "    model_styles=STYLES,\n",
    "    # legend_models_loc=\"upper left\",\n",
    "    legend_models_bbox=(0.27, .99),\n",
    "    # legend_bs_loc=\"lower left\",\n",
    "    legend_bs_bbox=(0.01, .25),\n",
    "    use_constrained_layout=True,\n",
    "    line_width=4.,\n",
    "    legend_fontsize=16,\n",
    "    axis_label_fontsize=23,\n",
    "    tick_label_fontsize=23,\n",
    ")\n",
    "\n",
    "for k,v in MODELS.items():\n",
    "    MODELS[k] = v.query('(bs >= 32) and (bs <= 1024)')\n",
    "minima_by_model = {name: build_minima_df(df, cfg) for name, df in MODELS.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd552c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_minima_at_horizon_across_models(minima_by_model, cfg, horizon=HORIZON)\n",
    "ax.set_xlim(4.7, 8.3)\n",
    "plt.show()\n",
    "# fig.savefig(f'plots/loss-vs-norm-scaling-for-horizon-{HORIZON}-from-fit-{FROM_FIT}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28944690",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_KEY = 'x32-d'\n",
    "fig, axes = plot_parabola_grid(MODELS[MODEL_KEY], cfg)\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.set_ylim(3.4, 5.5)  # Set your desired min and max values\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig(f'plots/fits-{MODEL_KEY}-from-fit-{FROM_FIT}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b9535c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
